<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visualizador de Audio e Imagen Avanzado con Three.js</title>
    <!-- Carga de Tailwind CSS para estilos básicos y responsivos -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden; /* Oculta barras de desplazamiento */
            font-family: 'Inter', sans-serif;
            background-color: #1a1a2e; /* Fondo oscuro */
            color: #e0e0e0;
        }
        canvas {
            display: block; /* Elimina el margen inferior por defecto del canvas */
            width: 100vw;
            height: 100vh;
            position: absolute;
            top: 0;
            left: 0;
            z-index: 0; /* Asegura que el canvas esté detrás de la UI */
        }
        #ui-container {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            z-index: 1; /* Asegura que la UI esté encima del canvas */
            background-color: rgba(0, 0, 0, 0.5); /* Superposición semitransparente */
            transition: opacity 0.5s ease-in-out; /* Transición suave para ocultar/mostrar */
        }
        .control-panel {
            background-color: rgba(30, 30, 50, 0.8);
            padding: 2rem;
            border-radius: 1rem;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);
            text-align: center;
            max-width: 90%;
            width: 500px;
        }
        .btn {
            background-color: #0f3460;
            color: white;
            padding: 0.8rem 1.5rem;
            border-radius: 0.5rem;
            border: none;
            cursor: pointer;
            font-size: 1rem;
            transition: background-color 0.3s ease, transform 0.2s ease;
            margin: 0.5rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);
        }
        .btn:hover {
            background-color: #16213e;
            transform: translateY(-2px);
        }
        .btn:active {
            transform: translateY(0);
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }
        input[type="file"] {
            margin-top: 1rem;
            padding: 0.5rem;
            border: 1px solid #0f3460;
            border-radius: 0.5rem;
            background-color: #2e2e4a;
            color: white;
            width: 80%; /* Ajuste para mejor visualización en móvil */
            max-width: 300px; /* Limitar ancho */
        }
        input[type="range"] {
            width: 80%;
            margin-top: 1rem;
            -webkit-appearance: none;
            height: 8px;
            background: #0f3460;
            border-radius: 5px;
            outline: none;
            opacity: 0.7;
            transition: opacity .2s;
        }
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: #e94560;
            cursor: pointer;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }
        input[type="range"]::-moz-range-thumb {
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: #e94560;
            cursor: pointer;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }
        #message-box {
            background-color: rgba(233, 69, 96, 0.9);
            color: white;
            padding: 1rem;
            border-radius: 0.5rem;
            position: absolute;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 100;
            display: none;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
            text-align: center;
        }

        /* Estilos para los controles de audio sutiles */
        #subtle-controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 10; /* Encima del canvas, debajo de la UI principal */
            background-color: rgba(30, 30, 50, 0.7);
            padding: 0.8rem 1.5rem;
            border-radius: 0.8rem;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
            display: flex;
            align-items: center;
            gap: 1rem; /* Espacio entre elementos */
            transition: opacity 0.5s ease-in-out;
            opacity: 0; /* Oculto por defecto */
            pointer-events: none; /* Permite clics a través cuando está oculto */
        }

        #subtle-controls .btn {
            padding: 0.6rem 1rem; /* Botones más pequeños */
            font-size: 0.9rem;
            margin: 0; /* Eliminar margen extra */
        }

        #subtle-controls input[type="range"] {
            width: 120px; /* Ancho fijo para el slider */
            margin: 0;
        }

        /* Mostrar los controles sutiles cuando sea necesario */
        #subtle-controls.visible {
            opacity: 1;
            pointer-events: auto; /* Habilita clics cuando está visible */
        }
    </style>
</head>
<body>
    <div id="message-box"></div>
    <div id="ui-container">
        <div class="control-panel">
            <h1 class="text-2xl font-bold mb-4">Visualizador de Audio e Imagen Avanzado</h1>
            <p class="mb-4">Carga tu propia pista de audio (MP3, WAV, OGG) y múltiples imágenes para ver el efecto.</p>
            
            <label for="audioFileInput" class="block text-left ml-auto mr-auto w-80 max-w-[300px] mb-2">Cargar Audio:</label>
            <input type="file" id="audioFileInput" accept="audio/*" class="mb-4">

            <label for="imageFileInput" class="block text-left ml-auto mr-auto w-80 max-w-[300px] mb-2">Cargar Imágenes (Primer Plano):</label>
            <input type="file" id="imageFileInput" accept="image/*" multiple class="mb-4">

            <label for="backgroundImageFileInput" class="block text-left ml-auto mr-auto w-80 max-w-[300px] mb-2">Cargar Imagen (Fondo):</label>
            <input type="file" id="backgroundImageFileInput" accept="image/*" class="mb-4">

            <div class="flex justify-center flex-wrap">
                <button id="playButton" class="btn">Reproducir</button>
                <button id="pauseButton" class="btn">Pausar</button>
                <button id="stopButton" class="btn">Detener</button>
            </div>
            <div class="mt-4">
                <label for="volumeControl" class="block mb-2">Volumen:</label>
                <input type="range" id="volumeControl" min="0" max="1" step="0.01" value="0.5">
            </div>
        </div>
    </div>

    <!-- Controles de audio sutiles -->
    <div id="subtle-controls">
        <button id="subtlePlayButton" class="btn">Reproducir</button>
        <button id="subtlePauseButton" class="btn">Pausar</button>
        <button id="subtleStopButton" class="btn">Detener</button>
        <div class="flex items-center gap-2">
            <label for="subtleVolumeControl" class="text-sm">Volumen:</label>
            <input type="range" id="subtleVolumeControl" min="0" max="1" step="0.01" value="0.5">
        </div>
    </div>

    <!-- Carga de Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- Carga de OrbitControls para interactividad de la cámara -->
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>

    <script type="module">
        // Variables globales para Three.js
        let scene, camera, renderer, controls;
        let planeMesh; // Malla del plano principal
        let backgroundSphereMesh; // Nueva malla para la esfera de fondo
        let uniforms; // Uniforms para el shader del plano principal
        let backgroundUniforms; // Uniforms para el shader de la esfera de fondo

        // Variables globales para Web Audio API
        let audioContext;
        let analyser;
        let audioSource;
        let gainNode;
        let audioBuffer; // Almacenará el buffer de audio cargado
        let isPlaying = false;

        // Variables de imágenes y transición (Plano Principal)
        let imageTextures = []; // Array para almacenar todas las texturas cargadas para el plano principal
        let currentTextureIndex = 0;
        let nextTextureIndex = 0;
        const TRANSITION_STATE = {
            IDLE: 0,
            FADE_OUT: 1,
            FADE_IN: 2
        };
        let transitionState = TRANSITION_STATE.IDLE;
        const transitionDuration = 3.0; // Duración total de la transición en segundos
        const minDisplayTime = 5.0; // Tiempo mínimo que una imagen se muestra antes de transicionar
        let lastTransitionTime = 0; // Tiempo en segundos desde el inicio de la animación

        // ...existing code...
        const uiContainer = document.getElementById('ui-container');
        const audioFileInput = document.getElementById('audioFileInput');
        const imageFileInput = document.getElementById('imageFileInput'); // Input para imágenes del plano principal
        const backgroundImageFileInput = document.getElementById('backgroundImageFileInput'); // Nuevo input para imagen de fondo
        const messageBox = document.getElementById('message-box');

        // Referencias a los botones y slider del panel de control principal
        const playButton = document.getElementById('playButton');
        const pauseButton = document.getElementById('pauseButton');
        const stopButton = document.getElementById('stopButton');
        const volumeControl = document.getElementById('volumeControl');

        // Referencias a los nuevos botones sutiles
        const subtleControls = document.getElementById('subtle-controls');
        const subtlePlayButton = document.getElementById('subtlePlayButton');
        const subtlePauseButton = document.getElementById('subtlePauseButton');
        const subtleStopButton = document.getElementById('subtleStopButton');
        const subtleVolumeControl = document.getElementById('subtleVolumeControl');
        // ...existing code...
        function showMessage(message, duration = 3000) {
            messageBox.textContent = message;
            messageBox.style.display = 'block';
            setTimeout(() => {
                messageBox.style.display = 'none';
            }, duration);
        }

        // --- Configuración de Three.js ---
        function initThreeJS() {
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x1a1a2e);
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.set(0, 0, 0);

            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            document.body.appendChild(renderer.domElement);
            controls = new THREE.OrbitControls(camera, renderer.domElement);
            controls.enableDamping = true;
            controls.dampingFactor = 0.05;
            controls.screenSpacePanning = false;
            controls.minDistance = 2;
            controls.maxDistance = 10;
            const ambientLight = new THREE.AmbientLight(0x404040);
            scene.add(ambientLight);
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.7);
            directionalLight.position.set(1, 1, 1).normalize();
            scene.add(directionalLight);
            const defaultTexture = new THREE.DataTexture(new Uint8Array([255, 255, 255, 255]), 1, 1, THREE.RGBAFormat);
            defaultTexture.needsUpdate = true;
            const planeGeometry = new THREE.PlaneGeometry(10, 10, 100, 100);

            uniforms = {
                u_time: { value: 0.0 },
                u_audioLevel: { value: 0.0 }, // Nivel de audio, de 0.0 a 1.0
                u_color1: { value: new THREE.Color(0x0f3460) }, // Color base
                u_color2: { value: new THREE.Color(0xe94560) },  // Color reactivo al audio
                u_currentTexture: { value: defaultTexture }, // Textura actual
                u_nextTexture: { value: defaultTexture },   // Textura a la que se transiciona
                u_transitionProgress: { value: 0.0 }, // Progreso de la transición (0.0 a 1.0)
                u_hasImages: { value: 0 } // 0: no hay imágenes cargadas, 1: hay imágenes
            };

            const vertexShaderPlane = `
                uniform float u_time;
                uniform float u_audioLevel;
                varying vec2 vUv;
                varying float vDisplacement;

                void main() {
                    vUv = uv;
                    // Calcula un desplazamiento basado en el tiempo y el nivel de audio
                    float displacement = sin(uv.x * 10.0 + u_time * 0.5) * cos(uv.y * 10.0 + u_time * 0.5) * u_audioLevel * 0.5;
                    // Aplica el desplazamiento a la posición Z de los vértices
                    vec3 newPosition = position + normal * displacement;
                    vDisplacement = displacement; // Pasa el desplazamiento al fragment shader
                    gl_Position = projectionMatrix * modelViewMatrix * vec4(newPosition, 1.0);
                }
            `;

            const fragmentShaderPlane = `
                uniform float u_time;
                uniform float u_audioLevel;
                uniform vec3 u_color1;
                uniform vec3 u_color2;
                uniform sampler2D u_currentTexture; // Uniforme para la textura actual
                uniform sampler2D u_nextTexture;    // Uniforme para la textura siguiente
                uniform float u_transitionProgress; // Progreso de la transición
                uniform int u_hasImages; // Uniforme para indicar si hay imágenes cargadas
                varying vec2 vUv;
                varying float vDisplacement;

                // Función de ruido para distorsión más compleja
                vec2 random2(vec2 st){
                    st = vec2( dot(st,vec2(127.1,311.7)),
                              dot(st,vec2(269.5,183.3)) );
                    return -1.0 + 2.0 * fract(sin(st)*43758.5453123);
                }

                float noise(vec2 st) {
                    vec2 i = floor(st);
                    vec2 f = fract(st);

                    vec2 u = f*f*(3.0-2.0*f);

                    return mix( mix( dot( random2(i + vec2(0.0,0.0)), f - vec2(0.0,0.0) ),
                                     dot( random2(i + vec2(1.0,0.0)), f - vec2(1.0,0.0) ), u.x),
                                mix( dot( random2(i + vec2(0.0,1.0)), f - vec2(0.0,1.0) ),
                                     dot( random2(i + vec2(1.0,1.0)), f - vec2(1.0,1.0) ), u.x), u.y);
                }

                void main() {
                    vec2 uv = vUv;
                    vec2 distortedUv = uv;

                    // Distorsión de las UVs basada en el audio y el tiempo
                    float audioDistortionStrength = u_audioLevel * 0.2; // Ajusta la fuerza de la distorsión del audio
                    float timeDistortionStrength = sin(u_time * 0.5) * 0.05 + 0.05; // Distorsión constante que varía con el tiempo

                    // Combinación de distorsiones para un efecto "irreconocible"
                    distortedUv.x += sin(uv.y * 20.0 + u_time * 1.5) * audioDistortionStrength;
                    distortedUv.y += cos(uv.x * 20.0 + u_time * 1.5) * audioDistortionStrength;
                    
                    // Añadir ruido para más caos
                    distortedUv += noise(uv * 5.0 + u_time * 0.2) * (audioDistortionStrength + timeDistortionStrength);
                    
                    // Distorsión adicional durante la transición para hacerla más caótica
                    float transitionDistortion = u_transitionProgress * (1.0 - u_transitionProgress) * 2.0; // Pico en el medio de la transición
                    distortedUv.x += sin(uv.y * 30.0 + u_time * 3.0) * transitionDistortion * 0.5;
                    distortedUv.y += cos(uv.x * 30.0 + u_time * 3.0) * transitionDistortion * 0.5;
                    distortedUv += noise(uv * 10.0 + u_time * 0.5) * transitionDistortion;


                    vec4 finalTextureColor;

                    if (u_hasImages == 0) { // Si no hay imágenes cargadas, usa los colores base
                        vec3 finalColor = mix(u_color1, u_color2, u_audioLevel + abs(vDisplacement));
                        gl_FragColor = vec4(finalColor, 1.0);
                    } else {
                        // Muestrear las texturas con las UVs distorsionadas
                        vec4 currentTextureColor = texture2D(u_currentTexture, distortedUv);
                        vec4 nextTextureColor = texture2D(u_nextTexture, distortedUv);

                        // Mezcla las texturas según el progreso de la transición
                        finalTextureColor = mix(currentTextureColor, nextTextureColor, u_transitionProgress);

                        // Aplicar cambio de color constante y reactivo al audio
                        // Esto es una rotación de color simple basada en el tiempo y el audio
                        vec3 colorShift = vec3(
                            sin(u_time * 2.0 + u_audioLevel * 5.0),
                            cos(u_time * 2.5 + u_audioLevel * 4.0),
                            sin(u_time * 3.0 + u_audioLevel * 3.0)
                        ) * 0.2; // Ajusta la intensidad del cambio de color

                        finalTextureColor.rgb += colorShift;
                        finalTextureColor.rgb = fract(finalTextureColor.rgb); // Para que los colores se "reinicien" y cambien constantemente
                        
                        // Mezcla el color de la textura con un factor basado en el desplazamiento geométrico
                        // Esto le da un matiz de color y hace que la distorsión geométrica sea visible en la imagen
                        finalTextureColor.rgb *= (1.0 + abs(vDisplacement) * 0.5);

                        gl_FragColor = finalTextureColor;
                    }
                }
            `;

            const shaderMaterialPlane = new THREE.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: vertexShaderPlane,
                fragmentShader: fragmentShaderPlane,
                wireframe: false // Puedes probar con true para ver la malla
            });

            planeMesh = new THREE.Mesh(planeGeometry, shaderMaterialPlane);
            planeMesh.rotation.x = -Math.PI / 2; // Rota el plano para que sea horizontal
            scene.add(planeMesh);

            // --- Esfera de Fondo (Segundo Plano) ---
            const backgroundSphereGeometry = new THREE.SphereGeometry(15, 64, 64); // Radio grande para que envuelva la escena
            backgroundSphereGeometry.scale(-1, 1, 1); // Invierte las normales para ver el interior de la esfera

            backgroundUniforms = {
                u_time: { value: 0.0 },
                u_audioLevel: { value: 0.0 },
                u_backgroundTexture: { value: defaultTexture }, // Textura para el fondo
                u_hasBackgroundTexture: { value: 0 }, // 0: no hay textura de fondo, 1: hay textura
                u_bgColor1: { value: new THREE.Color(0x16213e) }, // Color de fondo 1
                u_bgColor2: { value: new THREE.Color(0x0f3460) }  // Color de fondo 2 reactivo
            };

            const vertexShaderBackground = `
                uniform float u_time;
                uniform float u_audioLevel;
                varying vec2 vUv;

                void main() {
                    vUv = uv;
                    // Simple desplazamiento de vértices para la esfera de fondo
                    float displacement = sin(uv.x * 5.0 + u_time * 0.2) * cos(uv.y * 5.0 + u_time * 0.2) * u_audioLevel * 0.1;
                    vec3 newPosition = position + normal * displacement;
                    gl_Position = projectionMatrix * modelViewMatrix * vec4(newPosition, 1.0);
                }
            `;

            const fragmentShaderBackground = `
                uniform float u_time;
                uniform float u_audioLevel;
                uniform sampler2D u_backgroundTexture;
                uniform int u_hasBackgroundTexture;
                uniform vec3 u_bgColor1;
                uniform vec3 u_bgColor2;
                varying vec2 vUv;

                // Función de ruido para distorsión
                vec2 random2(vec2 st){
                    st = vec2( dot(st,vec2(127.1,311.7)),
                              dot(st,vec2(269.5,183.3)) );
                    return -1.0 + 2.0 * fract(sin(st)*43758.5453123);
                }

                float noise(vec2 st) {
                    vec2 i = floor(st);
                    vec2 f = fract(st);

                    vec2 u = f*f*(3.0-2.0*f);

                    return mix( mix( dot( random2(i + vec2(0.0,0.0)), f - vec2(0.0,0.0) ),
                                     dot( random2(i + vec2(1.0,0.0)), f - vec2(1.0,0.0) ), u.x),
                                mix( dot( random2(i + vec2(0.0,1.0)), f - vec2(0.0,1.0) ),
                                     dot( random2(i + vec2(1.0,1.0)), f - vec2(1.0,1.0) ), u.x), u.y);
                }

                void main() {
                    vec2 uv = vUv;
                    vec2 distortedUv = uv;

                    // Distorsión de las UVs para el fondo
                    float distortionStrength = u_audioLevel * 0.05 + 0.02; // Menos intenso que el primer plano
                    distortedUv.x += sin(uv.y * 15.0 + u_time * 0.5) * distortionStrength;
                    distortedUv.y += cos(uv.x * 15.0 + u_time * 0.5) * distortionStrength;
                    distortedUv += noise(uv * 3.0 + u_time * 0.1) * distortionStrength;

                    vec4 finalColor;

                    if (u_hasBackgroundTexture == 0) { // Si no hay textura de fondo personalizada
                        finalColor = vec4(mix(u_bgColor1, u_bgColor2, u_audioLevel), 1.0);
                    } else {
                        finalColor = texture2D(u_backgroundTexture, distortedUv);
                        // Aplicar un ligero cambio de color y mezcla con el audio
                        vec3 colorShift = vec3(
                            sin(u_time * 1.0 + u_audioLevel * 2.0),
                            cos(u_time * 1.2 + u_audioLevel * 1.5),
                            sin(u_time * 1.5 + u_audioLevel * 1.0)
                        ) * 0.1;
                        finalColor.rgb += colorShift;
                        finalColor.rgb = fract(finalColor.rgb);
                        finalColor.rgb = mix(finalColor.rgb, mix(u_bgColor1, u_bgColor2, u_audioLevel), 0.2); // Mezcla sutil con colores base
                    }
                    gl_FragColor = finalColor;
                }
            `;

            const shaderMaterialBackground = new THREE.ShaderMaterial({
                uniforms: backgroundUniforms,
                vertexShader: vertexShaderBackground,
                fragmentShader: fragmentShaderBackground,
                wireframe: false,
                side: THREE.BackSide // Renderiza el interior de la esfera
            });

            backgroundSphereMesh = new THREE.Mesh(backgroundSphereGeometry, shaderMaterialBackground);
            scene.add(backgroundSphereMesh);

            // Manejo del redimensionamiento de la ventana
            window.addEventListener('resize', onWindowResize, false);
        }

        // Función para manejar el redimensionamiento de la ventana
        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        // --- Configuración de Web Audio API ---
        function initAudio() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                gainNode = audioContext.createGain(); // Nodo de ganancia para control de volumen

                analyser.fftSize = 256; // Tamaño del FFT, afecta la granularidad de los datos de frecuencia
                const bufferLength = analyser.frequencyBinCount; // La mitad del fftSize
                const dataArray = new Uint8Array(bufferLength); // Array para almacenar los datos de frecuencia

                // Conecta el analizador al nodo de ganancia y luego al destino del audio
                analyser.connect(gainNode);
                gainNode.connect(audioContext.destination);

                // Establece el volumen inicial
                gainNode.gain.value = volumeControl.value; // Usar el control de volumen principal

                // Event listeners para los controles de volumen
                volumeControl.addEventListener('input', (event) => {
                    gainNode.gain.value = event.target.value;
                    subtleVolumeControl.value = event.target.value; // Sincronizar el control sutil
                });
                subtleVolumeControl.addEventListener('input', (event) => {
                    gainNode.gain.value = event.target.value;
                    volumeControl.value = event.target.value; // Sincronizar el control principal
                });


                // Event listener para cargar el archivo de audio
                audioFileInput.addEventListener('change', (event) => {
                    const file = event.target.files[0];
                    if (file) {
                        const reader = new FileReader();
                        reader.onload = (e) => {
                            audioContext.decodeAudioData(e.target.result, (buffer) => {
                                audioBuffer = buffer;
                                showMessage('Audio cargado. Haz clic en Reproducir.', 3000);
                                // Si ya hay una reproducción, deténla y reinicia para usar el nuevo buffer
                                if (isPlaying) {
                                    stopAudio();
                                }
                            }, (error) => {
                                console.error('Error al decodificar el audio:', error);
                                showMessage('Error al cargar el audio. Inténtalo de nuevo.', 5000);
                            });
                        };
                        reader.readAsArrayBuffer(file);
                    }
                });

                // Event listener para cargar múltiples archivos de imagen (Plano Principal)
                imageFileInput.addEventListener('change', (event) => {
                    const files = event.target.files;
                    if (files.length > 0) {
                        imageTextures = []; // Limpia las texturas anteriores
                        const textureLoader = new THREE.TextureLoader();
                        let loadedCount = 0;

                        for (let i = 0; i < files.length; i++) {
                            const file = files[i];
                            const reader = new FileReader();
                            reader.onload = (e) => {
                                textureLoader.load(e.target.result, (texture) => {
                                    imageTextures.push(texture);
                                    loadedCount++;
                                    if (loadedCount === files.length) {
                                        showMessage(`Se cargaron ${loadedCount} imágenes para el primer plano.`, 2000);
                                        uniforms.u_hasImages.value = 1; // Indica que hay imágenes cargadas
                                        // Establecer la primera imagen como la actual
                                        currentTextureIndex = 0;
                                        uniforms.u_currentTexture.value = imageTextures[currentTextureIndex];
                                        // Preparar la siguiente imagen para la transición inicial
                                        nextTextureIndex = (currentTextureIndex + 1) % imageTextures.length;
                                        uniforms.u_nextTexture.value = imageTextures[nextTextureIndex];
                                        lastTransitionTime = 0; // Reiniciar el tiempo de transición
                                        transitionState = TRANSITION_STATE.IDLE; // Empezar en estado IDLE
                                    }
                                }, undefined, (error) => {
                                    console.error('Error al cargar la imagen:', file.name, error);
                                    showMessage(`Error al cargar la imagen: ${file.name}.`, 5000);
                                    // Si una imagen falla, aún intentamos cargar las demás
                                    loadedCount++;
                                    if (loadedCount === files.length && imageTextures.length === 0) {
                                        uniforms.u_hasImages.value = 0; // Si ninguna imagen se cargó con éxito
                                        showMessage('No se pudo cargar ninguna imagen para el primer plano. Usando fondo de color.', 3000);
                                    }
                                });
                            };
                            reader.readAsDataURL(file);
                        }
                    } else {
                        // Si el usuario cancela la selección de archivo, restablece a la textura por defecto
                        imageTextures = [];
                        uniforms.u_currentTexture.value = new THREE.DataTexture(new Uint8Array([255, 255, 255, 255]), 1, 1, THREE.RGBAFormat);
                        uniforms.u_currentTexture.value.needsUpdate = true;
                        uniforms.u_nextTexture.value = new THREE.DataTexture(new Uint8Array([255, 255, 255, 255]), 1, 1, THREE.RGBAFormat);
                        uniforms.u_nextTexture.value.needsUpdate = true;
                        uniforms.u_hasImages.value = 0;
                        showMessage('Selección de imágenes para el primer plano cancelada. Usando fondo de color.', 2000);
                    }
                });

                // Event listener para cargar la imagen de fondo (Esfera de Fondo)
                backgroundImageFileInput.addEventListener('change', (event) => {
                    const file = event.target.files[0];
                    if (file) {
                        const reader = new FileReader();
                        reader.onload = (e) => {
                            const textureLoader = new THREE.TextureLoader();
                            textureLoader.load(e.target.result, (texture) => {
                                backgroundUniforms.u_backgroundTexture.value = texture;
                                backgroundUniforms.u_hasBackgroundTexture.value = 1; // Indica que se ha cargado una textura personalizada
                                showMessage('Imagen de fondo cargada.', 2000);
                            }, undefined, (error) => {
                                console.error('Error al cargar la imagen de fondo:', error);
                                showMessage('Error al cargar la imagen de fondo. Asegúrate de que sea un formato válido.', 5000);
                                backgroundUniforms.u_hasBackgroundTexture.value = 0; // Restablece si hay un error
                            });
                        };
                        reader.readAsDataURL(file); // Lee el archivo como una URL de datos
                    } else {
                        // Si el usuario cancela la selección de archivo, restablece a la textura por defecto
                        backgroundUniforms.u_backgroundTexture.value = new THREE.DataTexture(new Uint8Array([255, 255, 255, 255]), 1, 1, THREE.RGBAFormat);
                        backgroundUniforms.u_backgroundTexture.value.needsUpdate = true;
                        backgroundUniforms.u_hasBackgroundTexture.value = 0;
                        showMessage('Selección de imagen de fondo cancelada. Usando fondo de color.', 2000);
                    }
                });

                // Event listeners para los botones de control de audio (principal y sutil)
                playButton.addEventListener('click', playAudio);
                pauseButton.addEventListener('click', pauseAudio);
                stopButton.addEventListener('click', stopAudio);

                subtlePlayButton.addEventListener('click', playAudio);
                subtlePauseButton.addEventListener('click', pauseAudio);
                subtleStopButton.addEventListener('click', stopAudio);

            } catch (e) {
                console.error('Web Audio API no soportada en este navegador:', e);
                showMessage('Tu navegador no soporta la Web Audio API. Intenta con Chrome o Firefox.', 8000);
                // Deshabilita los controles si la API no está disponible
                audioFileInput.disabled = true;
                imageFileInput.disabled = true;
                backgroundImageFileInput.disabled = true;
                playButton.disabled = true;
                pauseButton.disabled = true;
                stopButton.disabled = true;
                volumeControl.disabled = true;
                subtlePlayButton.disabled = true;
                subtlePauseButton.disabled = true;
                subtleStopButton.disabled = true;
                subtleVolumeControl.disabled = true;
            }
        }

        // Función para reproducir el audio
        function playAudio() {
            if (!audioBuffer) {
                showMessage('Por favor, carga un archivo de audio primero.', 3000);
                return;
            }

            if (audioContext.state === 'suspended') {
                audioContext.resume(); // Reanuda el contexto si está suspendido (por interacción del usuario)
            }

            if (audioSource) {
                // Si ya hay una fuente, significa que está pausada o detenida.
                // Para reproducir desde el principio, necesitamos crear una nueva fuente.
                stopAudio(); // Detiene cualquier reproducción anterior
            }

            audioSource = audioContext.createBufferSource();
            audioSource.buffer = audioBuffer;
            audioSource.connect(analyser); // Conecta la fuente al analizador
            audioSource.loop = true; // Reproducción en bucle

            audioSource.start(0); // Inicia la reproducción desde el principio
            isPlaying = true;
            uiContainer.style.opacity = '0'; // Oculta la UI principal suavemente
            setTimeout(() => { uiContainer.style.display = 'none'; }, 500); // Espera la transición antes de ocultar completamente
            subtleControls.classList.add('visible'); // Muestra los controles sutiles
            showMessage('Reproduciendo audio...', 2000);
        }

        // Función para pausar el audio
        function pauseAudio() {
            if (audioSource && isPlaying) {
                audioContext.suspend(); // Suspende el contexto de audio
                isPlaying = false;
                uiContainer.style.display = 'flex'; // Muestra la UI principal
                uiContainer.style.opacity = '1'; // Muestra la UI principal suavemente
                subtleControls.classList.remove('visible'); // Oculta los controles sutiles
                showMessage('Audio pausado.', 2000);
            }
        }

        // Función para detener el audio
        function stopAudio() {
            if (audioSource) {
                audioSource.stop(); // Detiene la fuente de audio
                audioSource.disconnect(); // Desconecta la fuente
                audioSource = null; // Limpia la referencia
                isPlaying = false;
                audioContext.suspend(); // Suspende el contexto de audio para liberar recursos
                uiContainer.style.display = 'flex'; // Muestra la UI principal
                uiContainer.style.opacity = '1'; // Muestra la UI principal suavemente
                subtleControls.classList.remove('visible'); // Oculta los controles sutiles
            }
            // Reinicia el nivel de audio en los shaders cuando se detiene
            if (uniforms) {
                uniforms.u_audioLevel.value = 0.0;
                uniforms.u_transitionProgress.value = 0.0; // Reiniciar progreso de transición
                transitionState = TRANSITION_STATE.IDLE; // Reiniciar estado de transición
            }
            if (backgroundUniforms) {
                backgroundUniforms.u_audioLevel.value = 0.0;
            }
            showMessage('Audio detenido.', 2000);
        }

        // --- Bucle de Animación ---
        function animate() {
            requestAnimationFrame(animate);

            controls.update(); // Actualiza los controles de órbita

            // Actualizar el tiempo global para los shaders
            uniforms.u_time.value += 0.01;
            backgroundUniforms.u_time.value += 0.01;

            let audioLevel = 0.0;
            if (isPlaying && analyser) {
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                analyser.getByteFrequencyData(dataArray); // Obtiene los datos de frecuencia

                // Calcula el nivel de audio promedio
                let sum = 0;
                for (let i = 0; i < bufferLength; i++) {
                    sum += dataArray[i];
                }
                let average = sum / bufferLength;
                // Normaliza el promedio a un valor entre 0 y 1
                audioLevel = average / 255.0;

                // Rotación del plano principal
                planeMesh.rotation.z += audioLevel * 0.005; // Ajusta la velocidad de rotación
                planeMesh.rotation.x += audioLevel * 0.002; // Rotación en otro eje para más dinamismo
            } else {
                // Si no se está reproduciendo, el nivel de audio debería tender a cero
                if (uniforms.u_audioLevel.value > 0.01) {
                    audioLevel = uniforms.u_audioLevel.value * 0.95; // Disminuye gradualmente
                } else {
                    audioLevel = 0.0;
                }
            }

            // Actualiza el uniforme u_audioLevel en ambos shaders
            uniforms.u_audioLevel.value = audioLevel;
            backgroundUniforms.u_audioLevel.value = audioLevel;

            // Lógica de transición de imágenes (Plano Principal)
            if (imageTextures.length > 1 && isPlaying) { // Solo transiciona si hay más de una imagen y se está reproduciendo
                lastTransitionTime += 0.01; // Incrementa el tiempo transcurrido

                switch (transitionState) {
                    case TRANSITION_STATE.IDLE:
                        if (lastTransitionTime >= minDisplayTime) {
                            // Iniciar una nueva transición
                            transitionState = TRANSITION_STATE.FADE_OUT;
                            lastTransitionTime = 0; // Reiniciar el tiempo para la fase de transición
                            // Seleccionar la siguiente imagen aleatoriamente, asegurándose de que no sea la misma
                            let newNextIndex;
                            do {
                                newNextIndex = Math.floor(Math.random() * imageTextures.length);
                            } while (newNextIndex === currentTextureIndex);
                            nextTextureIndex = newNextIndex;
                            uniforms.u_nextTexture.value = imageTextures[nextTextureIndex];
                        }
                        uniforms.u_transitionProgress.value = 0.0; // Asegurarse de que no haya transición visible
                        break;

                    case TRANSITION_STATE.FADE_OUT:
                        // Progreso de 0.0 a 1.0 para el fade out
                        let progressOut = lastTransitionTime / (transitionDuration / 2.0); // La mitad del tiempo para fade out
                        uniforms.u_transitionProgress.value = Math.min(1.0, progressOut);

                        if (uniforms.u_transitionProgress.value >= 1.0) {
                            // Completa el fade out, cambia la textura actual y empieza el fade in
                            currentTextureIndex = nextTextureIndex;
                            uniforms.u_currentTexture.value = imageTextures[currentTextureIndex];
                            transitionState = TRANSITION_STATE.FADE_IN;
                            lastTransitionTime = 0; // Reiniciar el tiempo para la fase de transición
                        }
                        break;

                    case TRANSITION_STATE.FADE_IN:
                        // Progreso de 1.0 a 0.0 para el fade in (o de 0.0 a 1.0 para la mezcla, luego invertir)
                        let progressIn = lastTransitionTime / (transitionDuration / 2.0); // La otra mitad del tiempo para fade in
                        uniforms.u_transitionProgress.value = Math.min(1.0, progressIn); // Esto es el factor de mezcla para la nueva imagen

                        if (uniforms.u_transitionProgress.value >= 1.0) {
                            // Transición completa, volver a estado IDLE
                            transitionState = TRANSITION_STATE.IDLE;
                            lastTransitionTime = 0; // Reiniciar el tiempo para el estado IDLE
                            uniforms.u_transitionProgress.value = 0.0; // Asegurarse de que la transición esté en 0 al final
                        }
                        break;
                }
            } else if (imageTextures.length === 1 && isPlaying && uniforms.u_hasImages.value === 1) {
                // Si solo hay una imagen, asegúrate de que sea la actual y no haya transición
                uniforms.u_currentTexture.value = imageTextures[0];
                uniforms.u_nextTexture.value = imageTextures[0]; // Apunta a sí misma para evitar errores
                uniforms.u_transitionProgress.value = 0.0;
                transitionState = TRANSITION_STATE.IDLE;
            } else {
                // Si no hay imágenes o no se está reproduciendo, asegura que no haya transición
                uniforms.u_transitionProgress.value = 0.0;
                transitionState = TRANSITION_STATE.IDLE;
            }

            renderer.render(scene, camera); // Renderiza la escena
        }

        // Inicializa todo cuando la ventana se carga
        window.onload = function() {
            initThreeJS();
            initAudio();
            animate(); // Inicia el bucle de animación
            subtleControls.classList.remove('visible'); // Asegura que los controles sutiles estén ocultos al inicio
        };
    </script>
</body>
</html>
